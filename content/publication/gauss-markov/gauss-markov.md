+++
draft = false
selected = false
abstract = "In this lecture we will cover the Gauss-Markov theorem that establishes that out of the class of all linear unbiased estimators that the OLS estimator has minimum variance."
abstract_short = "In this lecture we will cover the Gauss-Markov theorem that establishes that out of the class of all linear unbiased estimators that the OLS estimator has minimum variance."
authors = ["Merlise Clyde"]
date = "2018-09-20"
image_preview = ""
math = true
publication_types = []
publication = ""
publication_short = ""
title = "Gauss-Markov and Minimum Variance Estimation"
url_code = "lectures/Gauss-Markov/estimability.Rmd"
url_dataset = ""
url_pdf = "http://getitatduke.library.duke.edu/?sid=sersol&SS_jc=TC0000508493&title=Plane%20Answers%20to%20Complex%20Questions%3A%20The%20Theory%20of%20Linear%20Models"
url_project = ""
url_slides = "lectures/Gauss-Markov/gm.pdf"
url_video = ""

# Optional featured image (relative to `static/img/` folder).
#[header]
#image = "headers/bubbles-wide.jpg"
#caption = "My caption :smile:"


+++

Readings: [Christensen Chapter 2 and Chapter 6, Appendix A & B as needed C](http://getitatduke.library.duke.edu/?sid=sersol&SS_jc=TC0000508493&title=Plane%20Answers%20to%20Complex%20Questions%3A%20The%20Theory%20of%20Linear%20Models)

In this lecture we will show that the MLEs are the best linear unbiased estimator through the Gauss-Markov Theorem and more generally under normality that they are the best unbiased estimator, where *best* means minimal variance.  We will look at how this applies for optimal prediction as well as estimates of linear combinations of parameters.



